{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine-similarity classifier [PyTorch]\n",
    "- feature extractor: ConvNet\n",
    "- classifier: cosine classifier (S. Gidaris et al., 2018)\n",
    "\n",
    "<b>Goal</b>: See if it can learn the representations effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import relu\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU settings\n",
    "device = torch.device(0)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot Learning Settings\n",
    "K-shot N-ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "N = 1\n",
    "left_class = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# import the `MNIST datasets`\n",
    "mnist_train = dsets.MNIST(root='data',\n",
    "                          train=True,\n",
    "                          transform=data_transform,\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='data',\n",
    "                          train=False,\n",
    "                          transform=data_transform,\n",
    "                          download=True)\n",
    "\n",
    "# build the `DataLoader`\n",
    "train_data_loader = DataLoader(mnist_train, batch_size=2**10)\n",
    "test_data_loader = DataLoader(mnist_test, batch_size=mnist_test.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daesoo\\AppData\\Local\\Programs\\Python\\Python37\\venvs\\pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoder\n",
    "label_encoder  = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = list(range(0, 10, 1))\n",
    "targets.pop(left_class)\n",
    "targets = np.array(targets).reshape(-1, 1)\n",
    "\n",
    "label_encoder.fit(targets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([5, 0, 4,  ..., 3, 7, 7])\n",
      "tensor(1.)\n",
      "torch.Size([1024, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data_loader:\n",
    "    print(x); print(y); print(x.max()); print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_size=28, embedding_feature_size=2, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Data properties\n",
    "        in_channels = 1\n",
    "        \n",
    "        # Define layers\n",
    "        # 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, 12, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.Dropout(0.2) #nn.BatchNorm2d(12)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 2\n",
    "        self.conv2 = nn.Conv2d(12, 24, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.Dropout(0.2) #nn.BatchNorm2d(24)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 3\n",
    "        self.conv3 = nn.Conv2d(24, 48, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.Dropout(0.0) #nn.BatchNorm2d(48)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 4\n",
    "        self.last_embedding_layer = nn.Linear(48*3*3, embedding_feature_size)\n",
    "        \n",
    "        # Each `w` is a representation vector of each class.\n",
    "        self.Wstar_layer = nn.Linear(embedding_feature_size, n_classes, bias=False)  # 'bias=False' allows the weights to be the pure representation vectors (not affected by the bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #============================\n",
    "        # Feature Extractor\n",
    "        h1 = self.maxpool1(relu(self.bn1(self.conv1(x))))\n",
    "        h2 = self.maxpool2(relu(self.bn2(self.conv2(h1))))\n",
    "        h3 = self.maxpool3(relu(self.bn3(self.conv3(h2))))\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        h3 = h3.view(batch_size, -1)  # 1\n",
    "        \n",
    "        self.z = self.last_embedding_layer(h3)\n",
    "        norm_z = self.z / torch.norm(self.z, p=2, dim=1, keepdim=True)#.detach() # 2)\n",
    "        \n",
    "        # 1) flattne layer\n",
    "        # 2) representation vector of `x`; Note `.detach()`: ; We don't want the l2-norm function to be involved with the gradient descent update.\n",
    "        \n",
    "        #============================\n",
    "        # Cosine-similarity Classifier\n",
    "        Wstar = self.Wstar_layer.weight.T#.detach()  # Note `.detach()`\n",
    "        norm_Wstar = Wstar / torch.norm(Wstar, p=2, dim=0, keepdim=True)\n",
    "        \n",
    "        cosine_similarities = torch.mm(norm_z, norm_Wstar)\n",
    "        # Note that `CrossEntropyLoss()` = `LogSoftmax` + `NLLLoss`\n",
    "        return cosine_similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(embedding_feature_size=64, n_classes=9).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayRate = 1.0\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, \n",
    "                                                         gamma=decayRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature parameter\n",
    "tau = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "study effects of the temperature parameter\n",
    "- Note that the temperature parameters of 0.1 / 0.2 result in the best performance given the SimCLR and MoCo-v2 papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "yhat = model(x.to(device))\n",
    "yhat = yhat[0, :].to(\"cpu\").detach().numpy()\n",
    "x_ = np.arange(yhat.size)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9, 6))\n",
    "ax[0,0].bar(x_, softmax(yhat), label=r\"w/o $\\tau$\"); ax[0,0].legend();\n",
    "ax[1,0].bar(x_, softmax(yhat/0.1), label=r\"$\\tau$ = 0.1\"); ax[1,0].legend();\n",
    "ax[1,1].bar(x_, softmax(yhat/0.2), label=r\"$\\tau$ = 0.2\"); ax[1,1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "n_epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_out_a_class(x, y, left_class):\n",
    "    \"leave out some class for the few-shot learning\"\n",
    "    indices = (y != left_class)\n",
    "    return x[indices, :, :, :], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.734, test_acc: 0.947 | lr: 0.0010\n",
      "epoch: 1, loss: 0.126, test_acc: 0.960 | lr: 0.0010\n",
      "epoch: 2, loss: 0.094, test_acc: 0.973 | lr: 0.0010\n",
      "epoch: 3, loss: 0.076, test_acc: 0.973 | lr: 0.0010\n",
      "epoch: 4, loss: 0.066, test_acc: 0.983 | lr: 0.0010\n",
      "epoch: 5, loss: 0.058, test_acc: 0.984 | lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "train_hist = {\"epochs\": [], \"loss_per_epoch\": [], \"loss\": [], \"test_acc\": []}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    loss_per_epoch = 0\n",
    "    iters = 0\n",
    "    for x, y in train_data_loader:\n",
    "        x, y = leave_out_a_class(x, y, left_class)\n",
    "        y = torch.tensor(label_encoder.transform(y))\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        yhat = model(x)\n",
    "        \n",
    "        loss = criterion(yhat/tau, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # data storage\n",
    "        loss_per_epoch += loss\n",
    "        iters += 1\n",
    "        train_hist[\"loss\"].append(loss)\n",
    "        #print(round(loss.item(), 2), end=\" \")\n",
    "            \n",
    "    train_hist[\"epochs\"].append(epoch)\n",
    "    train_hist[\"loss_per_epoch\"].append(loss_per_epoch)\n",
    "    \n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_acc = 0\n",
    "        for x_test, y_test in test_data_loader:\n",
    "            x_test, y_test = leave_out_a_class(x_test, y_test, left_class)\n",
    "            y_test = torch.tensor(label_encoder.transform(y_test))\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            yhat = torch.argmax(model(x_test.to(device)), axis=1)\n",
    "            test_acc += np.mean((yhat.to(\"cpu\") == y_test.to(\"cpu\")).numpy())\n",
    "        train_hist[\"test_acc\"].append(test_acc)\n",
    "    \n",
    "    my_lr_scheduler.step()\n",
    "    \n",
    "    print(\"epoch: {}, loss: {:0.3f}, test_acc: {:0.3f} | lr: {:0.4f}\".format(epoch, loss_per_epoch/iters, test_acc, optimizer.param_groups[0]['lr']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make `support set` and `query set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = (mnist_test.targets == left_class)\n",
    "\n",
    "class SupportSet(Dataset):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        \n",
    "        support_set_X = []\n",
    "        support_set_Y = []\n",
    "        for c in range(0, 10):\n",
    "            indices = (mnist_test.targets == c)\n",
    "            support_set_X.append( mnist_test.data[indices, :, :][:N, :, :].numpy() / 255. )\n",
    "            support_set_Y.append( mnist_test.targets[indices][:N].numpy() )\n",
    "\n",
    "        self.support_set_X = torch.from_numpy(np.array(support_set_X)).view(N*10, 1, 28, 28)\n",
    "        self.support_set_Y = torch.from_numpy(np.array(support_set_Y).flatten())\n",
    "\n",
    "        self.len = self.support_set_X.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.support_set_X[idx], self.support_set_Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "support_set = SupportSet()\n",
    "support_set_data_loader = DataLoader(support_set, batch_size=2**10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain $w_{left-class}$\n",
    "Note $w_i \\in W^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    avg_z = 0.\n",
    "    count = 0\n",
    "    for x, y in support_set:\n",
    "        if y.item() == left_class:\n",
    "            enc_yhat = model(x.view(1, 1, 28, 28).to(device, dtype=torch.float))\n",
    "            avg_z += model.z\n",
    "            count += 1\n",
    "    avg_z /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-establish $W^*$ \n",
    "- `model.Wstar_layer.weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Wstar_layer.weight.shape  # [in, out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 64])\n",
      "torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "font_Wstar = model.Wstar_layer.weight[:left_class, :]\n",
    "back_Wstar = model.Wstar_layer.weight[left_class:, :]\n",
    "\n",
    "print(font_Wstar.shape); print(back_Wstar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "res_Wstar = torch.cat((font_Wstar, avg_z, back_Wstar), 0).to(device)\n",
    "print(res_Wstar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the `res_Wstar` to the existing model\n",
    "model.Wstar_layer.weight = nn.Parameter(res_Wstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the learned representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`left_class` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    indices = (mnist_test.targets == left_class)\n",
    "    \n",
    "    test_acc = 0\n",
    "    count = 0\n",
    "    for x_test, y_test in test_data_loader:\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "        x_test, y_test = x_test[indices,:,:], y_test[indices]\n",
    "        \n",
    "        yhat = torch.argmax(model(x_test.to(device)), axis=1)\n",
    "        \n",
    "        test_acc += np.mean((yhat.to(\"cpu\") == y_test.to(\"cpu\")).numpy())\n",
    "        count += 1\n",
    "        \n",
    "    test_acc /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8385214007782101"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0 | acc: 0.995\n",
      "class: 1 | acc: 0.996\n",
      "class: 2 | acc: 0.974\n",
      "class: 3 | acc: 0.957\n",
      "class: 4 | acc: 0.994\n",
      "class: 5 | acc: 0.989\n",
      "class: 6 | acc: 0.982\n",
      "class: 7 | acc: 0.839\n",
      "class: 8 | acc: 0.947\n",
      "class: 9 | acc: 0.959\n",
      "\n",
      " overall acc: 0.963\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    test_accs = []\n",
    "    for c in range(10):\n",
    "        indices = (mnist_test.targets == c)\n",
    "    \n",
    "        test_acc = 0\n",
    "        count = 0\n",
    "        for x_test, y_test in test_data_loader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            x_test, y_test = x_test[indices,:,:], y_test[indices]\n",
    "\n",
    "            yhat = torch.argmax(model(x_test.to(device)), axis=1)\n",
    "\n",
    "            test_acc += np.mean((yhat.to(\"cpu\") == y_test.to(\"cpu\")).numpy())\n",
    "            count += 1\n",
    "\n",
    "        test_acc /= count\n",
    "        test_accs.append(test_acc)\n",
    "        print(f\"class: {c} | acc: {round(test_acc, 3)}\")\n",
    "\n",
    "print(\"\\n overall acc: {:0.3f}\".format(np.mean(test_accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b>: With the `temperature`, the quality of the learned representations is much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the learned representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`left_class` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    indices = (mnist_test.targets == left_class)\n",
    "    \n",
    "    test_acc = 0\n",
    "    count = 0\n",
    "    for x_test, y_test in test_data_loader:\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "        x_test, y_test = x_test[indices,:,:], y_test[indices]\n",
    "        \n",
    "        yhat = torch.argmax(model(x_test.to(device)), axis=1)\n",
    "        \n",
    "        test_acc += np.mean((yhat.to(\"cpu\") == y_test.to(\"cpu\")).numpy())\n",
    "        count += 1\n",
    "        \n",
    "    test_acc /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8385214007782101"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0 | acc: 0.995\n",
      "class: 1 | acc: 0.996\n",
      "class: 2 | acc: 0.974\n",
      "class: 3 | acc: 0.957\n",
      "class: 4 | acc: 0.994\n",
      "class: 5 | acc: 0.989\n",
      "class: 6 | acc: 0.982\n",
      "class: 7 | acc: 0.839\n",
      "class: 8 | acc: 0.947\n",
      "class: 9 | acc: 0.959\n",
      "\n",
      " overall acc: 0.963\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    test_accs = []\n",
    "    for c in range(10):\n",
    "        indices = (mnist_test.targets == c)\n",
    "    \n",
    "        test_acc = 0\n",
    "        count = 0\n",
    "        for x_test, y_test in test_data_loader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            x_test, y_test = x_test[indices,:,:], y_test[indices]\n",
    "\n",
    "            yhat = torch.argmax(model(x_test.to(device)), axis=1)\n",
    "\n",
    "            test_acc += np.mean((yhat.to(\"cpu\") == y_test.to(\"cpu\")).numpy())\n",
    "            count += 1\n",
    "\n",
    "        test_acc /= count\n",
    "        test_accs.append(test_acc)\n",
    "        print(f\"class: {c} | acc: {round(test_acc, 3)}\")\n",
    "\n",
    "print(\"\\n overall acc: {:0.3f}\".format(np.mean(test_accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b>: The performance degraded than the prior approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
